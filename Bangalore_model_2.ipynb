{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6  Part 1: Multiple Linear Regression Modeling\n",
    "I'm running a normality plot on the prices to review the validity of regression.\n",
    "\n",
    "1\n",
    "places2 = places.iloc[1:1850, 3:48]\n",
    "2\n",
    "newprice = places['Price']\n",
    "3\n",
    "model1 = smf.ols(\"Price~UID+Area+Region+Bedrooms+Resale+MaintenanceStaff+Gymnasium+SwimmingPool+LandscapedGardens+JoggingTrack+RainWaterHarvesting+IndoorGames+ShoppingMall+Intercom+SportsFacility+ATM+ClubHouse+School+X24X7Security+PowerBackup+CarParking+StaffQuarter+Cafeteria+MultipurposeRoom+Hospital+WashingMachine+Gasconnection+AC+Wifi+Childrensplayarea+LiftAvailable+BED+VaastuCompliant+Microwave+GolfCourse+TV+DiningTable+Sofa+Wardrobe+Refrigerator+Furniture+Fitness+Appliances+Entertain\",data=places).fit()\n",
    "4\n",
    "model1.summary()\n",
    "OLS Regression Results\n",
    "Dep. Variable:\tPrice\tR-squared:\t0.867\n",
    "Model:\tOLS\tAdj. R-squared:\t0.864\n",
    "Method:\tLeast Squares\tF-statistic:\t311.5\n",
    "Date:\tSun, 10 Oct 2021\tProb (F-statistic):\t0.00\n",
    "Time:\t16:18:17\tLog-Likelihood:\t-31195.\n",
    "No. Observations:\t1856\tAIC:\t6.247e+04\n",
    "Df Residuals:\t1817\tBIC:\t6.268e+04\n",
    "Df Model:\t38\t\t\n",
    "Covariance Type:\tnonrobust\t\t\n",
    "coef\tstd err\tt\tP>|t|\t[0.025\t0.975]\n",
    "Intercept\t-6.929e+06\t7.48e+05\t-9.259\t0.000\t-8.4e+06\t-5.46e+06\n",
    "Region[T.East]\t-1.104e+06\t4.65e+05\t-2.372\t0.018\t-2.02e+06\t-1.91e+05\n",
    "Region[T.North]\t6.022e+05\t4.77e+05\t1.263\t0.207\t-3.33e+05\t1.54e+06\n",
    "Region[T.Northeast]\t5.402e+04\t1.05e+06\t0.051\t0.959\t-2.01e+06\t2.12e+06\n",
    "Region[T.South]\t-1.371e+06\t3.29e+05\t-4.169\t0.000\t-2.02e+06\t-7.26e+05\n",
    "Region[T.Southeast]\t-1.396e+06\t5.33e+05\t-2.622\t0.009\t-2.44e+06\t-3.52e+05\n",
    "Region[T.West]\t-3.342e+05\t5.62e+05\t-0.594\t0.552\t-1.44e+06\t7.69e+05\n",
    "UID\t359.9692\t223.908\t1.608\t0.108\t-79.174\t799.112\n",
    "Area\t1.753e+04\t220.065\t79.670\t0.000\t1.71e+04\t1.8e+04\n",
    "Bedrooms\t-4.041e+06\t2.44e+05\t-16.568\t0.000\t-4.52e+06\t-3.56e+06\n",
    "Resale\t-6.857e+05\t6.36e+05\t-1.077\t0.281\t-1.93e+06\t5.62e+05\n",
    "MaintenanceStaff\t1.748e+05\t4.17e+05\t0.420\t0.675\t-6.42e+05\t9.92e+05\n",
    "Gymnasium\t4.907e+05\t5.85e+05\t0.838\t0.402\t-6.57e+05\t1.64e+06\n",
    "SwimmingPool\t2.091e+06\t4.45e+05\t4.702\t0.000\t1.22e+06\t2.96e+06\n",
    "LandscapedGardens\t-4.405e+06\t3.74e+05\t-11.772\t0.000\t-5.14e+06\t-3.67e+06\n",
    "JoggingTrack\t2.64e+05\t3.94e+05\t0.669\t0.503\t-5.09e+05\t1.04e+06\n",
    "RainWaterHarvesting\t2.278e+06\t3.56e+05\t6.401\t0.000\t1.58e+06\t2.98e+06\n",
    "IndoorGames\t4.98e+05\t3.12e+05\t1.596\t0.111\t-1.14e+05\t1.11e+06\n",
    "ShoppingMall\t3.067e+06\t5.23e+05\t5.867\t0.000\t2.04e+06\t4.09e+06\n",
    "Intercom\t9.915e+05\t3.46e+05\t2.868\t0.004\t3.13e+05\t1.67e+06\n",
    "SportsFacility\t2.387e+04\t3.54e+05\t0.067\t0.946\t-6.7e+05\t7.18e+05\n",
    "ATM\t-1.744e+06\t4.99e+05\t-3.494\t0.000\t-2.72e+06\t-7.65e+05\n",
    "ClubHouse\t8.309e+04\t4e+05\t0.208\t0.836\t-7.02e+05\t8.68e+05\n",
    "School\t-2.869e+06\t8.69e+05\t-3.302\t0.001\t-4.57e+06\t-1.17e+06\n",
    "X24X7Security\t6.814e+04\t4.14e+05\t0.164\t0.869\t-7.45e+05\t8.81e+05\n",
    "PowerBackup\t1.534e+06\t5.81e+05\t2.638\t0.008\t3.93e+05\t2.67e+06\n",
    "CarParking\t9.283e+05\t3.19e+05\t2.910\t0.004\t3.03e+05\t1.55e+06\n",
    "StaffQuarter\t3.714e+05\t4.35e+05\t0.854\t0.393\t-4.82e+05\t1.22e+06\n",
    "Cafeteria\t-1.738e+06\t3.31e+05\t-5.258\t0.000\t-2.39e+06\t-1.09e+06\n",
    "MultipurposeRoom\t-1.152e+06\t3.23e+05\t-3.567\t0.000\t-1.79e+06\t-5.19e+05\n",
    "Hospital\t-1.448e+06\t1.06e+06\t-1.372\t0.170\t-3.52e+06\t6.23e+05\n",
    "WashingMachine\t7.739e+05\t4.49e+05\t1.723\t0.085\t-1.07e+05\t1.65e+06\n",
    "Gasconnection\t-6.601e+05\t4.99e+05\t-1.324\t0.186\t-1.64e+06\t3.18e+05\n",
    "AC\t-1.202e+06\t1.97e+06\t-0.609\t0.543\t-5.07e+06\t2.67e+06\n",
    "Wifi\t9.339e-10\t3.02e-10\t3.089\t0.002\t3.41e-10\t1.53e-09\n",
    "Childrensplayarea\t-1.139e+06\t4.56e+05\t-2.498\t0.013\t-2.03e+06\t-2.45e+05\n",
    "LiftAvailable\t-2.053e+06\t4.15e+05\t-4.951\t0.000\t-2.87e+06\t-1.24e+06\n",
    "BED\t-4.282e+06\t1.88e+06\t-2.281\t0.023\t-7.96e+06\t-6.01e+05\n",
    "VaastuCompliant\t-9.852e+05\t3.39e+05\t-2.908\t0.004\t-1.65e+06\t-3.21e+05\n",
    "Microwave\t7.739e+05\t4.49e+05\t1.723\t0.085\t-1.07e+05\t1.65e+06\n",
    "GolfCourse\t-2.782e+06\t6.58e+05\t-4.231\t0.000\t-4.07e+06\t-1.49e+06\n",
    "TV\t7.739e+05\t4.49e+05\t1.723\t0.085\t-1.07e+05\t1.65e+06\n",
    "DiningTable\t7.739e+05\t4.49e+05\t1.723\t0.085\t-1.07e+05\t1.65e+06\n",
    "Sofa\t7.739e+05\t4.49e+05\t1.723\t0.085\t-1.07e+05\t1.65e+06\n",
    "Wardrobe\t0\t0\tnan\tnan\t0\t0\n",
    "Refrigerator\t7.739e+05\t4.49e+05\t1.723\t0.085\t-1.07e+05\t1.65e+06\n",
    "Furniture\t-2.734e+06\t1.55e+06\t-1.768\t0.077\t-5.77e+06\t2.99e+05\n",
    "Fitness\t8.732e+04\t1.78e+05\t0.489\t0.625\t-2.63e+05\t4.37e+05\n",
    "Appliances\t1.894e+06\t1.03e+06\t1.834\t0.067\t-1.32e+05\t3.92e+06\n",
    "Entertain\t6.884e+05\t1.93e+05\t3.571\t0.000\t3.1e+05\t1.07e+06\n",
    "Omnibus:\t1616.681\tDurbin-Watson:\t1.125\n",
    "Prob(Omnibus):\t0.000\tJarque-Bera (JB):\t135599.071\n",
    "Skew:\t3.638\tProb(JB):\t0.00\n",
    "Kurtosis:\t44.237\tCond. No.\t1.08e+16\n",
    "\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The smallest eigenvalue is 5.96e-23. This might indicate that there are\n",
    "strong multicollinearity problems or that the design matrix is singular.\n",
    "We run the initial linear regression model with all 45 variables. The model was not as robust as expected. We are going to review the details below. Use our correlation matrix to eliminate variables with high correlation and create a robust smaller model.\n",
    "\n",
    "1\n",
    "#run regression and looking at the normality plot\n",
    "2\n",
    "​\n",
    "3\n",
    "​\n",
    "4\n",
    "fig = plt.figure(figsize= (10, 10))\n",
    "5\n",
    "ax = fig.add_subplot(111)\n",
    "6\n",
    "​\n",
    "7\n",
    "normality_plot, stat = stats.probplot(model.resid, plot= plt, rvalue= True)\n",
    "8\n",
    "ax.set_title(\"Probability plot of model residual's\", fontsize= 20)\n",
    "9\n",
    "ax.set\n",
    "10\n",
    "​\n",
    "11\n",
    "plt.show()\n",
    "\n",
    "Next I wanted to see how the number Entertainment features available was spread through the regions. It appears the Northeast has the most by far followed by North and Southeast.\n",
    "\n",
    "Now I'm comparing the housing sizes and it appears once again the Central is dominating followed by Southeast and North. This is making me wonder if the Northeast is more of a \"college town\" like atmosposhere with very small housing but lots of entertainment near by.\n",
    "\n",
    "1.6.1  Initial Linear Regression Model\n",
    "We contnue to improve the model focusing on a subset of variables based on correlation and the explanation was included above.\n",
    "\n",
    "1\n",
    "#Run a complete regression model of all variables\n",
    "2\n",
    "​\n",
    "3\n",
    "#smf.ols(Price~Area+Region+No..of.Bedrooms+Fitness+Appliances+Furniture+RainWaterHarvesting+School+VaastuCompliant+Intercom+LiftAvailable+ShoppingMall+ATM+PowerBackup+MultipurposeRoom+CarParking+LandscapedGardens,\n",
    "4\n",
    "        #data = places).fit()\n",
    "5\n",
    "model = smf.ols(\"Price~Area+Region+Bedrooms+Fitness+Appliances+Furniture+RainWaterHarvesting+School+VaastuCompliant+Intercom+LiftAvailable+ShoppingMall+ATM+PowerBackup+MultipurposeRoom+CarParking+LandscapedGardens\",\n",
    "6\n",
    "        data = places).fit()\n",
    "7\n",
    "model.summary()\n",
    "OLS Regression Results\n",
    "Dep. Variable:\tPrice\tR-squared:\t0.861\n",
    "Model:\tOLS\tAdj. R-squared:\t0.860\n",
    "Method:\tLeast Squares\tF-statistic:\t517.9\n",
    "Date:\tSun, 10 Oct 2021\tProb (F-statistic):\t0.00\n",
    "Time:\t16:18:18\tLog-Likelihood:\t-31232.\n",
    "No. Observations:\t1856\tAIC:\t6.251e+04\n",
    "Df Residuals:\t1833\tBIC:\t6.264e+04\n",
    "Df Model:\t22\t\t\n",
    "Covariance Type:\tnonrobust\t\t\n",
    "coef\tstd err\tt\tP>|t|\t[0.025\t0.975]\n",
    "Intercept\t-7.26e+06\t6.68e+05\t-10.860\t0.000\t-8.57e+06\t-5.95e+06\n",
    "Region[T.East]\t-1.213e+06\t4.57e+05\t-2.652\t0.008\t-2.11e+06\t-3.16e+05\n",
    "Region[T.North]\t8.856e+05\t4.56e+05\t1.944\t0.052\t-7819.952\t1.78e+06\n",
    "Region[T.Northeast]\t-8.932e+04\t9.97e+05\t-0.090\t0.929\t-2.04e+06\t1.87e+06\n",
    "Region[T.South]\t-9.045e+05\t3.16e+05\t-2.867\t0.004\t-1.52e+06\t-2.86e+05\n",
    "Region[T.Southeast]\t-1.182e+06\t5.02e+05\t-2.357\t0.019\t-2.17e+06\t-1.99e+05\n",
    "Region[T.West]\t1.933e+05\t5.19e+05\t0.372\t0.710\t-8.24e+05\t1.21e+06\n",
    "Area\t1.744e+04\t218.881\t79.679\t0.000\t1.7e+04\t1.79e+04\n",
    "Bedrooms\t-3.87e+06\t2.43e+05\t-15.948\t0.000\t-4.35e+06\t-3.39e+06\n",
    "Fitness\t5.621e+05\t1.37e+05\t4.088\t0.000\t2.92e+05\t8.32e+05\n",
    "Appliances\t2.781e+06\t1.93e+06\t1.444\t0.149\t-9.96e+05\t6.56e+06\n",
    "Furniture\t-4.711e+06\t3.21e+06\t-1.468\t0.142\t-1.1e+07\t1.58e+06\n",
    "RainWaterHarvesting\t2.551e+06\t3.22e+05\t7.913\t0.000\t1.92e+06\t3.18e+06\n",
    "School\t-3.151e+06\t5.21e+05\t-6.052\t0.000\t-4.17e+06\t-2.13e+06\n",
    "VaastuCompliant\t-1.088e+06\t3e+05\t-3.626\t0.000\t-1.68e+06\t-4.99e+05\n",
    "Intercom\t1.04e+06\t3.29e+05\t3.163\t0.002\t3.95e+05\t1.68e+06\n",
    "LiftAvailable\t-2.344e+06\t3.9e+05\t-6.012\t0.000\t-3.11e+06\t-1.58e+06\n",
    "ShoppingMall\t3.095e+06\t5.45e+05\t5.680\t0.000\t2.03e+06\t4.16e+06\n",
    "ATM\t-1.676e+06\t4.68e+05\t-3.579\t0.000\t-2.59e+06\t-7.58e+05\n",
    "PowerBackup\t2.312e+06\t5.26e+05\t4.395\t0.000\t1.28e+06\t3.34e+06\n",
    "MultipurposeRoom\t-4.551e+05\t3.07e+05\t-1.482\t0.138\t-1.06e+06\t1.47e+05\n",
    "CarParking\t8.384e+05\t2.88e+05\t2.908\t0.004\t2.73e+05\t1.4e+06\n",
    "LandscapedGardens\t-4.113e+06\t3.32e+05\t-12.389\t0.000\t-4.76e+06\t-3.46e+06\n",
    "Omnibus:\t1649.210\tDurbin-Watson:\t1.113\n",
    "Prob(Omnibus):\t0.000\tJarque-Bera (JB):\t146093.125\n",
    "Skew:\t3.743\tProb(JB):\t0.00\n",
    "Kurtosis:\t45.815\tCond. No.\t5.53e+04\n",
    "\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The condition number is large, 5.53e+04. This might indicate that there are\n",
    "strong multicollinearity or other numerical problems.\n",
    "By reviewing the previous model created with multiple regression, I dropped all the variables with high P values. The improved model that I created shows below and it is my final model. The p value of the overall model is small and ensures that the linear model is appropriate, all the coefficients of the model are largers so we don't have any unwanted effects. The R squared of the model is 86% and given that the model is not overfitted this R squared is optimal. The model that we created had 22 variables. We managed to limit the initial 45 but we will continue with one more step.\n",
    "\n",
    "1.6.2  Final Linear Regression Model\n",
    "1\n",
    "#Final model. Low F statistic. High Rsquared 86%. All P values are small. All coefficients are large\n",
    "2\n",
    "model2 = smf.ols(\"Price~Area+Region+Bedrooms+Fitness+RainWaterHarvesting+School+VaastuCompliant+Intercom+LiftAvailable+ShoppingMall+ATM+PowerBackup+CarParking+LandscapedGardens\",\n",
    "3\n",
    "        data = places).fit()\n",
    "4\n",
    "model2.summary()\n",
    "OLS Regression Results\n",
    "Dep. Variable:\tPrice\tR-squared:\t0.861\n",
    "Model:\tOLS\tAdj. R-squared:\t0.860\n",
    "Method:\tLeast Squares\tF-statistic:\t598.9\n",
    "Date:\tSun, 10 Oct 2021\tProb (F-statistic):\t0.00\n",
    "Time:\t16:18:18\tLog-Likelihood:\t-31235.\n",
    "No. Observations:\t1856\tAIC:\t6.251e+04\n",
    "Df Residuals:\t1836\tBIC:\t6.262e+04\n",
    "Df Model:\t19\t\t\n",
    "Covariance Type:\tnonrobust\t\t\n",
    "coef\tstd err\tt\tP>|t|\t[0.025\t0.975]\n",
    "Intercept\t-7.357e+06\t6.57e+05\t-11.191\t0.000\t-8.65e+06\t-6.07e+06\n",
    "Region[T.East]\t-1.205e+06\t4.57e+05\t-2.636\t0.008\t-2.1e+06\t-3.08e+05\n",
    "Region[T.North]\t9.699e+05\t4.53e+05\t2.141\t0.032\t8.16e+04\t1.86e+06\n",
    "Region[T.Northeast]\t-3.448e+05\t9.81e+05\t-0.352\t0.725\t-2.27e+06\t1.58e+06\n",
    "Region[T.South]\t-8.826e+05\t3.15e+05\t-2.799\t0.005\t-1.5e+06\t-2.64e+05\n",
    "Region[T.Southeast]\t-1.14e+06\t4.98e+05\t-2.287\t0.022\t-2.12e+06\t-1.62e+05\n",
    "Region[T.West]\t2.195e+05\t5.17e+05\t0.425\t0.671\t-7.94e+05\t1.23e+06\n",
    "Area\t1.744e+04\t217.907\t80.055\t0.000\t1.7e+04\t1.79e+04\n",
    "Bedrooms\t-3.866e+06\t2.43e+05\t-15.930\t0.000\t-4.34e+06\t-3.39e+06\n",
    "Fitness\t5.08e+05\t1.32e+05\t3.845\t0.000\t2.49e+05\t7.67e+05\n",
    "RainWaterHarvesting\t2.473e+06\t3.13e+05\t7.892\t0.000\t1.86e+06\t3.09e+06\n",
    "School\t-3.196e+06\t5.2e+05\t-6.141\t0.000\t-4.22e+06\t-2.18e+06\n",
    "VaastuCompliant\t-1.184e+06\t2.89e+05\t-4.102\t0.000\t-1.75e+06\t-6.18e+05\n",
    "Intercom\t1.12e+06\t3.21e+05\t3.493\t0.000\t4.91e+05\t1.75e+06\n",
    "LiftAvailable\t-2.315e+06\t3.84e+05\t-6.023\t0.000\t-3.07e+06\t-1.56e+06\n",
    "ShoppingMall\t3.115e+06\t5.44e+05\t5.724\t0.000\t2.05e+06\t4.18e+06\n",
    "ATM\t-1.662e+06\t4.68e+05\t-3.551\t0.000\t-2.58e+06\t-7.44e+05\n",
    "PowerBackup\t2.319e+06\t5.26e+05\t4.408\t0.000\t1.29e+06\t3.35e+06\n",
    "CarParking\t7.74e+05\t2.86e+05\t2.706\t0.007\t2.13e+05\t1.33e+06\n",
    "LandscapedGardens\t-4.152e+06\t3.3e+05\t-12.589\t0.000\t-4.8e+06\t-3.51e+06\n",
    "Omnibus:\t1656.452\tDurbin-Watson:\t1.109\n",
    "Prob(Omnibus):\t0.000\tJarque-Bera (JB):\t147737.611\n",
    "Skew:\t3.768\tProb(JB):\t0.00\n",
    "Kurtosis:\t46.053\tCond. No.\t1.53e+04\n",
    "\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The condition number is large, 1.53e+04. This might indicate that there are\n",
    "strong multicollinearity or other numerical problems.\n",
    "Here I again want to look at descriptive statistics for the major predictors.\n",
    "\n",
    "1\n",
    "places[[\"Area\", \"Bedrooms\", \"Fitness\"]].describe()\n",
    "Area\tBedrooms\tFitness\n",
    "count\t1856.000000\t1856.000000\t1856.000000\n",
    "mean\t1508.585129\t2.522091\t3.014009\n",
    "std\t776.867104\t0.680532\t1.157569\n",
    "min\t525.000000\t1.000000\t0.000000\n",
    "25%\t1139.000000\t2.000000\t3.000000\n",
    "50%\t1307.500000\t2.000000\t3.000000\n",
    "75%\t1590.000000\t3.000000\t4.000000\n",
    "max\t9900.000000\t5.000000\t5.000000\n",
    "1\n",
    "places_small = places[[\"Price\", \"Area\", \"Fitness\", \"Bedrooms\"]]\n",
    "2\n",
    "places_small.head()\n",
    "Price\tArea\tFitness\tBedrooms\n",
    "0\t5599000\t1120\t0\t2\n",
    "1\t7837000\t1866\t5\t3\n",
    "2\t9834000\t2235\t5\t3\n",
    "3\t8298999\t1976\t5\t3\n",
    "4\t8728000\t2182\t5\t3\n",
    "1.6.3  Zooming into the final model\n",
    "Focusing only on the variables that are predictors for the prices I further reviewed their correlations I created a heat map and correlation matrix.\n",
    "\n",
    "1\n",
    "sns.pairplot(places_small)\n",
    "<seaborn.axisgrid.PairGrid at 0x22c57833700>\n",
    "\n",
    "1\n",
    "#The prices are distorted because of some apartments in the Central regions. May want to review the data to increase the number of bins appropriately\n",
    "2\n",
    "plt.hist(places[\"Price\"], bins=300)\n",
    "(array([ 27.,  79., 127., 189., 202., 147., 160., 149., 116.,  93.,  89.,\n",
    "         55.,  36.,  52.,  39.,  26.,  11.,  28.,  13.,  13.,  15.,   5.,\n",
    "          4.,   7.,   4.,   6.,  12.,   3.,   8.,   6.,   6.,   9.,   8.,\n",
    "          1.,   4.,   6.,   2.,   3.,   5.,   5.,   3.,   7.,   3.,   3.,\n",
    "          4.,   0.,   2.,   5.,   2.,   3.,   4.,   2.,   2.,   0.,   1.,\n",
    "          1.,   2.,   3.,   1.,   1.,   1.,   1.,   0.,   0.,   2.,   2.,\n",
    "          2.,   0.,   0.,   1.,   0.,   4.,   1.,   1.,   1.,   0.,   1.,\n",
    "          0.,   0.,   0.,   0.,   1.,   1.,   1.,   0.,   0.,   1.,   0.,\n",
    "          2.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
    "          2.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
    "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,\n",
    "          0.,   0.,   1.]),\n",
    " array([2.0960000e+06, 2.7646800e+06, 3.4333600e+06, 4.1020400e+06,\n",
    "        4.7707200e+06, 5.4394000e+06, 6.1080800e+06, 6.7767600e+06,\n",
    "        7.4454400e+06, 8.1141200e+06, 8.7828000e+06, 9.4514800e+06,\n",
    "        1.0120160e+07, 1.0788840e+07, 1.1457520e+07, 1.2126200e+07,\n",
    "        1.2794880e+07, 1.3463560e+07, 1.4132240e+07, 1.4800920e+07,\n",
    "        1.5469600e+07, 1.6138280e+07, 1.6806960e+07, 1.7475640e+07,\n",
    "        1.8144320e+07, 1.8813000e+07, 1.9481680e+07, 2.0150360e+07,\n",
    "        2.0819040e+07, 2.1487720e+07, 2.2156400e+07, 2.2825080e+07,\n",
    "        2.3493760e+07, 2.4162440e+07, 2.4831120e+07, 2.5499800e+07,\n",
    "        2.6168480e+07, 2.6837160e+07, 2.7505840e+07, 2.8174520e+07,\n",
    "        2.8843200e+07, 2.9511880e+07, 3.0180560e+07, 3.0849240e+07,\n",
    "        3.1517920e+07, 3.2186600e+07, 3.2855280e+07, 3.3523960e+07,\n",
    "        3.4192640e+07, 3.4861320e+07, 3.5530000e+07, 3.6198680e+07,\n",
    "        3.6867360e+07, 3.7536040e+07, 3.8204720e+07, 3.8873400e+07,\n",
    "        3.9542080e+07, 4.0210760e+07, 4.0879440e+07, 4.1548120e+07,\n",
    "        4.2216800e+07, 4.2885480e+07, 4.3554160e+07, 4.4222840e+07,\n",
    "        4.4891520e+07, 4.5560200e+07, 4.6228880e+07, 4.6897560e+07,\n",
    "        4.7566240e+07, 4.8234920e+07, 4.8903600e+07, 4.9572280e+07,\n",
    "        5.0240960e+07, 5.0909640e+07, 5.1578320e+07, 5.2247000e+07,\n",
    "        5.2915680e+07, 5.3584360e+07, 5.4253040e+07, 5.4921720e+07,\n",
    "        5.5590400e+07, 5.6259080e+07, 5.6927760e+07, 5.7596440e+07,\n",
    "        5.8265120e+07, 5.8933800e+07, 5.9602480e+07, 6.0271160e+07,\n",
    "        6.0939840e+07, 6.1608520e+07, 6.2277200e+07, 6.2945880e+07,\n",
    "        6.3614560e+07, 6.4283240e+07, 6.4951920e+07, 6.5620600e+07,\n",
    "        6.6289280e+07, 6.6957960e+07, 6.7626640e+07, 6.8295320e+07,\n",
    "        6.8964000e+07, 6.9632680e+07, 7.0301360e+07, 7.0970040e+07,\n",
    "        7.1638720e+07, 7.2307400e+07, 7.2976080e+07, 7.3644760e+07,\n",
    "        7.4313440e+07, 7.4982120e+07, 7.5650800e+07, 7.6319480e+07,\n",
    "        7.6988160e+07, 7.7656840e+07, 7.8325520e+07, 7.8994200e+07,\n",
    "        7.9662880e+07, 8.0331560e+07, 8.1000240e+07, 8.1668920e+07,\n",
    "        8.2337600e+07, 8.3006280e+07, 8.3674960e+07, 8.4343640e+07,\n",
    "        8.5012320e+07, 8.5681000e+07, 8.6349680e+07, 8.7018360e+07,\n",
    "        8.7687040e+07, 8.8355720e+07, 8.9024400e+07, 8.9693080e+07,\n",
    "        9.0361760e+07, 9.1030440e+07, 9.1699120e+07, 9.2367800e+07,\n",
    "        9.3036480e+07, 9.3705160e+07, 9.4373840e+07, 9.5042520e+07,\n",
    "        9.5711200e+07, 9.6379880e+07, 9.7048560e+07, 9.7717240e+07,\n",
    "        9.8385920e+07, 9.9054600e+07, 9.9723280e+07, 1.0039196e+08,\n",
    "        1.0106064e+08, 1.0172932e+08, 1.0239800e+08, 1.0306668e+08,\n",
    "        1.0373536e+08, 1.0440404e+08, 1.0507272e+08, 1.0574140e+08,\n",
    "        1.0641008e+08, 1.0707876e+08, 1.0774744e+08, 1.0841612e+08,\n",
    "        1.0908480e+08, 1.0975348e+08, 1.1042216e+08, 1.1109084e+08,\n",
    "        1.1175952e+08, 1.1242820e+08, 1.1309688e+08, 1.1376556e+08,\n",
    "        1.1443424e+08, 1.1510292e+08, 1.1577160e+08, 1.1644028e+08,\n",
    "        1.1710896e+08, 1.1777764e+08, 1.1844632e+08, 1.1911500e+08,\n",
    "        1.1978368e+08, 1.2045236e+08, 1.2112104e+08, 1.2178972e+08,\n",
    "        1.2245840e+08, 1.2312708e+08, 1.2379576e+08, 1.2446444e+08,\n",
    "        1.2513312e+08, 1.2580180e+08, 1.2647048e+08, 1.2713916e+08,\n",
    "        1.2780784e+08, 1.2847652e+08, 1.2914520e+08, 1.2981388e+08,\n",
    "        1.3048256e+08, 1.3115124e+08, 1.3181992e+08, 1.3248860e+08,\n",
    "        1.3315728e+08, 1.3382596e+08, 1.3449464e+08, 1.3516332e+08,\n",
    "        1.3583200e+08, 1.3650068e+08, 1.3716936e+08, 1.3783804e+08,\n",
    "        1.3850672e+08, 1.3917540e+08, 1.3984408e+08, 1.4051276e+08,\n",
    "        1.4118144e+08, 1.4185012e+08, 1.4251880e+08, 1.4318748e+08,\n",
    "        1.4385616e+08, 1.4452484e+08, 1.4519352e+08, 1.4586220e+08,\n",
    "        1.4653088e+08, 1.4719956e+08, 1.4786824e+08, 1.4853692e+08,\n",
    "        1.4920560e+08, 1.4987428e+08, 1.5054296e+08, 1.5121164e+08,\n",
    "        1.5188032e+08, 1.5254900e+08, 1.5321768e+08, 1.5388636e+08,\n",
    "        1.5455504e+08, 1.5522372e+08, 1.5589240e+08, 1.5656108e+08,\n",
    "        1.5722976e+08, 1.5789844e+08, 1.5856712e+08, 1.5923580e+08,\n",
    "        1.5990448e+08, 1.6057316e+08, 1.6124184e+08, 1.6191052e+08,\n",
    "        1.6257920e+08, 1.6324788e+08, 1.6391656e+08, 1.6458524e+08,\n",
    "        1.6525392e+08, 1.6592260e+08, 1.6659128e+08, 1.6725996e+08,\n",
    "        1.6792864e+08, 1.6859732e+08, 1.6926600e+08, 1.6993468e+08,\n",
    "        1.7060336e+08, 1.7127204e+08, 1.7194072e+08, 1.7260940e+08,\n",
    "        1.7327808e+08, 1.7394676e+08, 1.7461544e+08, 1.7528412e+08,\n",
    "        1.7595280e+08, 1.7662148e+08, 1.7729016e+08, 1.7795884e+08,\n",
    "        1.7862752e+08, 1.7929620e+08, 1.7996488e+08, 1.8063356e+08,\n",
    "        1.8130224e+08, 1.8197092e+08, 1.8263960e+08, 1.8330828e+08,\n",
    "        1.8397696e+08, 1.8464564e+08, 1.8531432e+08, 1.8598300e+08,\n",
    "        1.8665168e+08, 1.8732036e+08, 1.8798904e+08, 1.8865772e+08,\n",
    "        1.8932640e+08, 1.8999508e+08, 1.9066376e+08, 1.9133244e+08,\n",
    "        1.9200112e+08, 1.9266980e+08, 1.9333848e+08, 1.9400716e+08,\n",
    "        1.9467584e+08, 1.9534452e+08, 1.9601320e+08, 1.9668188e+08,\n",
    "        1.9735056e+08, 1.9801924e+08, 1.9868792e+08, 1.9935660e+08,\n",
    "        2.0002528e+08, 2.0069396e+08, 2.0136264e+08, 2.0203132e+08,\n",
    "        2.0270000e+08]),\n",
    " <BarContainer object of 300 artists>)\n",
    "\n",
    "Based on heatmap it appears that the number of bedrooms and total area within the housing are the most important factors in the pricing. The number of bedrooms has a moderate impact. The number of fitness centers have almost no impact.\n",
    "\n",
    "1\n",
    "sns.heatmap(places_small.corr(), annot=True)\n",
    "<AxesSubplot:>\n",
    "\n",
    "1.6.4  Conclusion of Multi Linear Regression Model\n",
    "I started with lots of data and some of it was messy. But after cleaning it up a bit and performing the exploritory data analysis I was able to see strong trends. One is particular was how much more expensive it is to be in the central region compared to everywhere else. I can get a sense of income levels and what types of areas these are but not totally conclusive. There is more work I can do to find that out. But housing prices are strongly tied to the size of a home and the area it's located. There are several other factors such as number of bedrooms that have a moderat impact and others like fitness centers in the area that have almost no impact. Also some area have a much higher degree of variance in prices than others.\n",
    "\n",
    "1.7  Part 2: Machine Learning\n",
    "1.7.1  Data Preparation for Machine Learning Algorithms\n",
    "At this point I'm preparing the data and especially the categorical values for a logistic regression. I'm going to use the dummy method to introduce binary artificial valriables for each one of our categorical variables.\n",
    "\n",
    "1\n",
    "dummies = pd.get_dummies(places[\"Region\"])\n",
    "2\n",
    "dummies.head()\n",
    "Central\tEast\tNorth\tNortheast\tSouth\tSoutheast\tWest\n",
    "0\t1\t0\t0\t0\t0\t0\t0\n",
    "1\t1\t0\t0\t0\t0\t0\t0\n",
    "2\t1\t0\t0\t0\t0\t0\t0\n",
    "3\t1\t0\t0\t0\t0\t0\t0\n",
    "4\t1\t0\t0\t0\t0\t0\t0\n",
    "1\n",
    "dummies = pd.get_dummies(places[\"Location\"])\n",
    "2\n",
    "dummies.head()\n",
    "Amruthahalli\tAnagalapura Near Hennur Main Road\tAnekal City\tAnjanapura\tAttibele\tAvalahalli Off Sarjapur Road\tBTM Layout\tBadamanavarthekaval\tBanashankari\tBanaswadi\t...\tTalaghattapura\tThanisandra\tUttarahalli\tUttarahalli Hobli\tVarthur\tVidyaranyapura\tWhitefield\tWhitefield Hope Farm Junction\tYelahanka\tYerthiganahalli\n",
    "0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
    "1\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
    "2\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
    "3\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
    "4\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
    "5 rows × 102 columns\n",
    "\n",
    "1\n",
    "dummies = pd.get_dummies(places[\"Resale\"])\n",
    "2\n",
    "dummies.head()\n",
    "0\t1\n",
    "0\t1\t0\n",
    "1\t1\t0\n",
    "2\t1\t0\n",
    "3\t1\t0\n",
    "4\t1\t0\n",
    "1.7.2  Logistic Regression\n",
    "Response variable \"Region\" identifying predictors. I will start my machine learning part of the project trying to verify the results of the previous work. My goal here is to build a process that learns the region where a property is located using all the other variables including the price of the properties. The region is a qualitative variable with 7 different values. We have already seen that the prices on some of the regions overlap and predicting prices based on the ammenities of the properties was not easy. What I'd like to do here is to reveal any possible predictors (ammenities) or price that would identify the region of the property. For this purpose I will use a logistic regression.\n",
    "\n",
    "We prepare to run a logistric regression. Our response variable is the region. We are going to develope a model based on the data received. It will predict the region that the property lays.\n",
    "\n",
    "1\n",
    "places1 = places.drop(['UID', 'Region'], axis=1)\n",
    "2\n",
    "places1.head()\n",
    "Price\tArea\tLocation\tBedrooms\tResale\tMaintenanceStaff\tGymnasium\tSwimmingPool\tLandscapedGardens\tJoggingTrack\t...\tGolfCourse\tTV\tDiningTable\tSofa\tWardrobe\tRefrigerator\tFurniture\tFitness\tAppliances\tEntertain\n",
    "0\t5599000\t1120\tAmruthahalli\t2\t0\t0\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
    "1\t7837000\t1866\tAnagalapura Near Hennur Main Road\t3\t0\t0\t1\t1\t1\t1\t...\t1\t0\t0\t0\t0\t0\t0\t5\t0\t3\n",
    "2\t9834000\t2235\tAnagalapura Near Hennur Main Road\t3\t0\t0\t1\t1\t1\t1\t...\t1\t0\t0\t0\t0\t0\t0\t5\t0\t3\n",
    "3\t8298999\t1976\tAnagalapura Near Hennur Main Road\t3\t0\t0\t1\t1\t1\t1\t...\t1\t0\t0\t0\t0\t0\t0\t5\t0\t3\n",
    "4\t8728000\t2182\tAnagalapura Near Hennur Main Road\t3\t0\t0\t1\t1\t1\t1\t...\t1\t0\t0\t0\t0\t0\t0\t5\t0\t3\n",
    "5 rows × 44 columns\n",
    "\n",
    "1\n",
    "places2 = places.drop(['UID'], axis=1)\n",
    "2\n",
    "X = pd.concat([places2._get_numeric_data(),dummies],axis=1)\n",
    "3\n",
    "y = places2.Region\n",
    "4\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)\n",
    "1\n",
    "# build scaler based on training data and apply it to test data to then also scale the test data\n",
    "2\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "3\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "4\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "1\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state = 1,n_jobs=-1)\n",
    "2\n",
    "model_res = clf.fit(X_train_scaled, y_train)\n",
    "3\n",
    "y_pred = model_res.predict(X_test_scaled)\n",
    "4\n",
    "y_pred_prob = model_res.predict_proba(X_test_scaled)\n",
    "5\n",
    "lr_probs = y_pred_prob[:,1]\n",
    "6\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "7\n",
    "​\n",
    "8\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "9\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "10\n",
    "​\n",
    "11\n",
    "print('Random Forest: Accuracy=%.3f' % (ac))\n",
    "12\n",
    "​\n",
    "13\n",
    "print('Random Forest: f1-score=%.3f' % (f1))\n",
    "Random Forest: Accuracy=0.935\n",
    "Random Forest: f1-score=0.935\n",
    "1\n",
    "class_names=['North', 'East', 'South', 'West', 'Northeast', 'Southeast', 'Central']\n",
    "1\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "2\n",
    "                          normalize=False,\n",
    "3\n",
    "                          title='Confusion matrix',\n",
    "4\n",
    "                          cmap=plt.cm.Blues):\n",
    "5\n",
    "    \"\"\"\n",
    "6\n",
    "    This function prints and plots the confusion matrix.\n",
    "7\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "8\n",
    "    \"\"\"\n",
    "9\n",
    "    if normalize:\n",
    "10\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "11\n",
    "        print(\"Normalized confusion matrix\")\n",
    "12\n",
    "    else:\n",
    "13\n",
    "        print('Confusion matrix, without normalization')\n",
    "14\n",
    "​\n",
    "15\n",
    "    print(cm)\n",
    "16\n",
    "​\n",
    "17\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "18\n",
    "    plt.title(title)\n",
    "19\n",
    "    plt.colorbar()\n",
    "20\n",
    "    tick_marks = np.arange(len(classes))\n",
    "21\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "22\n",
    "    plt.yticks(tick_marks, classes)\n",
    "23\n",
    "​\n",
    "24\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "25\n",
    "    thresh = cm.max() / 2.\n",
    "26\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "27\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "28\n",
    "                 horizontalalignment=\"center\",\n",
    "29\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "30\n",
    "​\n",
    "31\n",
    "    plt.ylabel('True label')\n",
    "32\n",
    "    plt.xlabel('Predicted label')\n",
    "33\n",
    "    plt.tight_layout()\n",
    "34\n",
    "​\n",
    "35\n",
    "​\n",
    "36\n",
    "# Compute confusion matrix\n",
    "37\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "38\n",
    "np.set_printoptions(precision=2)\n",
    "39\n",
    "​\n",
    "40\n",
    "# Plot non-normalized confusion matrix\n",
    "41\n",
    "plt.figure()\n",
    "42\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "43\n",
    "                      title='Confusion matrix, without normalization')\n",
    "44\n",
    "#plt.savefig('figures/RF_cm_multi_class.png')\n",
    "45\n",
    "​\n",
    "46\n",
    "# Plot normalized confusion matrix\n",
    "47\n",
    "plt.figure()\n",
    "48\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "49\n",
    "                      title='Normalized confusion matrix')\n",
    "50\n",
    "#plt.savefig('figures/RF_cm_proportion_multi_class.png', bbox_inches=\"tight\")\n",
    "51\n",
    "plt.show()\n",
    "Confusion matrix, without normalization\n",
    "[[ 85   1   0   0   6   0   1]\n",
    " [  1  33   2   0   2   0   0]\n",
    " [  3   0  29   0   0   0   0]\n",
    " [  0   0   0   5   0   0   0]\n",
    " [  2   1   0   0 120   0   1]\n",
    " [  0   0   0   0   0  28   0]\n",
    " [  1   0   0   0   3   0  48]]\n",
    "Normalized confusion matrix\n",
    "[[0.91 0.01 0.   0.   0.06 0.   0.01]\n",
    " [0.03 0.87 0.05 0.   0.05 0.   0.  ]\n",
    " [0.09 0.   0.91 0.   0.   0.   0.  ]\n",
    " [0.   0.   0.   1.   0.   0.   0.  ]\n",
    " [0.02 0.01 0.   0.   0.97 0.   0.01]\n",
    " [0.   0.   0.   0.   0.   1.   0.  ]\n",
    " [0.02 0.   0.   0.   0.06 0.   0.92]]\n",
    "\n",
    "\n",
    "1\n",
    "feature_importance = clf.feature_importances_\n",
    "2\n",
    "# make importances relative to max importance\n",
    "3\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "4\n",
    "sorted_idx = np.argsort(feature_importance)[:30]\n",
    "5\n",
    "​\n",
    "6\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "7\n",
    "print(pos.size)\n",
    "8\n",
    "sorted_idx.size\n",
    "9\n",
    "plt.figure(figsize=(10,10))\n",
    "10\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "11\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "12\n",
    "plt.xlabel('Relative Importance')\n",
    "13\n",
    "plt.title('Variable Importance')\n",
    "14\n",
    "plt.show()\n",
    "30\n",
    "\n",
    "1.7.2.1  Conclusion of Logistic Regression\n",
    "I ran a logistic regressio to predict the region of a given apartment/house using the set of 40 variables. The results were quite interesting and had a very high accuracy of 93.5%. The main predictor of the region is the price of the apartment. Although somebody would expect the area to also be one of the most important predictors this doesn't seem to be the case. We can see that variables that define if a region is cosmopolitan area are the ones that are good predictors.\n",
    "\n",
    "1.7.3  Linear Regression of the price with Gradient Boosting\n",
    "I'm going to run an OLS, a linear regression model with gradient boosting. The model will learn to predict prices based on the most important variables. Initially it runs with the prices of all the properties. The learned model gave me standard outliers in our predictions. In order to make the model more accurate and not dependant on outliers I reviewed the prices and identified 117 extreme outliers. This was less than 6% of the total observations. I decided to drop the outliers from the initial model and run the learning without them.\n",
    "\n",
    "1\n",
    "temp = places['Price']\n",
    "2\n",
    "print(temp)\n",
    "3\n",
    "temp.sort_values()\n",
    "0        5599000\n",
    "1        7837000\n",
    "2        9834000\n",
    "3        8298999\n",
    "4        8728000\n",
    "          ...   \n",
    "1851    10600000\n",
    "1852     9200000\n",
    "1853    10100000\n",
    "1854    10300000\n",
    "1855     9799000\n",
    "Name: Price, Length: 1856, dtype: int64\n",
    "45       2096000\n",
    "201      2157000\n",
    "511      2253000\n",
    "523      2254000\n",
    "522      2254000\n",
    "         ...    \n",
    "700    170000000\n",
    "687    170600000\n",
    "688    182300000\n",
    "697    198600000\n",
    "699    202700000\n",
    "Name: Price, Length: 1856, dtype: int64\n",
    "1\n",
    "Q1 = temp.quantile(0.25)\n",
    "2\n",
    "Q3 = temp.quantile(0.75)\n",
    "3\n",
    "IQR = Q3 - Q1\n",
    "4\n",
    "print(IQR)\n",
    "4669750.0\n",
    "1\n",
    "sum((temp<(Q1 - 3 * IQR))|(temp>(Q3 + 3 * IQR)))\n",
    "2\n",
    "threshold  = Q3 + 3 * IQR\n",
    "3\n",
    "print(threshold)\n",
    "23576500.0\n",
    "1\n",
    "sns.boxplot(x=temp)\n",
    "<AxesSubplot:xlabel='Price'>\n",
    "\n",
    "1\n",
    "placesClean = places[places['Price'] < threshold]\n",
    "2\n",
    "placesClean.head()\n",
    "UID\tPrice\tArea\tLocation\tRegion\tBedrooms\tResale\tMaintenanceStaff\tGymnasium\tSwimmingPool\t...\tGolfCourse\tTV\tDiningTable\tSofa\tWardrobe\tRefrigerator\tFurniture\tFitness\tAppliances\tEntertain\n",
    "0\t341\t5599000\t1120\tAmruthahalli\tCentral\t2\t0\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
    "1\t304\t7837000\t1866\tAnagalapura Near Hennur Main Road\tCentral\t3\t0\t0\t1\t1\t...\t1\t0\t0\t0\t0\t0\t0\t5\t0\t3\n",
    "2\t305\t9834000\t2235\tAnagalapura Near Hennur Main Road\tCentral\t3\t0\t0\t1\t1\t...\t1\t0\t0\t0\t0\t0\t0\t5\t0\t3\n",
    "3\t306\t8298999\t1976\tAnagalapura Near Hennur Main Road\tCentral\t3\t0\t0\t1\t1\t...\t1\t0\t0\t0\t0\t0\t0\t5\t0\t3\n",
    "4\t307\t8728000\t2182\tAnagalapura Near Hennur Main Road\tCentral\t3\t0\t0\t1\t1\t...\t1\t0\t0\t0\t0\t0\t0\t5\t0\t3\n",
    "5 rows × 46 columns\n",
    "\n",
    "1\n",
    "dummies = pd.get_dummies(placesClean[\"Region\"])\n",
    "2\n",
    "X_all = placesClean.drop([\"UID\", \"Location\", \"Region\", \"Wifi\", \"Appliances\", \"Wardrobe\", \"Price\"],axis=1)\n",
    "3\n",
    "y = placesClean.Price\n",
    "4\n",
    "​\n",
    "5\n",
    "​\n",
    "6\n",
    "X = pd.concat([X_all,dummies], axis=1)\n",
    "7\n",
    "# Create constants for X, so the model knows its bounds\n",
    "8\n",
    "X = sm.add_constant(X)\n",
    "9\n",
    "​\n",
    "10\n",
    "# Split the data\n",
    "11\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 123)\n",
    "12\n",
    "print(X)\n",
    "      const  Area  Bedrooms  Resale  MaintenanceStaff  Gymnasium  \\\n",
    "0       1.0  1120         2       0                 0          0   \n",
    "1       1.0  1866         3       0                 0          1   \n",
    "2       1.0  2235         3       0                 0          1   \n",
    "3       1.0  1976         3       0                 0          1   \n",
    "4       1.0  2182         3       0                 0          1   \n",
    "...     ...   ...       ...     ...               ...        ...   \n",
    "1851    1.0  1635         3       0                 0          1   \n",
    "1852    1.0  1475         3       0                 0          1   \n",
    "1853    1.0  1560         3       0                 0          1   \n",
    "1854    1.0  1620         3       0                 0          1   \n",
    "1855    1.0  1274         2       0                 0          1   \n",
    "\n",
    "      SwimmingPool  LandscapedGardens  JoggingTrack  RainWaterHarvesting  ...  \\\n",
    "0                0                  0             0                    0  ...   \n",
    "1                1                  1             1                    1  ...   \n",
    "2                1                  1             1                    1  ...   \n",
    "3                1                  1             1                    1  ...   \n",
    "4                1                  1             1                    1  ...   \n",
    "...            ...                ...           ...                  ...  ...   \n",
    "1851             1                  1             0                    0  ...   \n",
    "1852             1                  1             0                    0  ...   \n",
    "1853             1                  1             0                    0  ...   \n",
    "1854             1                  1             0                    0  ...   \n",
    "1855             1                  0             0                    0  ...   \n",
    "\n",
    "      Furniture  Fitness  Entertain  Central  East  North  Northeast  South  \\\n",
    "0             0        0          0        1     0      0          0      0   \n",
    "1             0        5          3        1     0      0          0      0   \n",
    "2             0        5          3        1     0      0          0      0   \n",
    "3             0        5          3        1     0      0          0      0   \n",
    "4             0        5          3        1     0      0          0      0   \n",
    "...         ...      ...        ...      ...   ...    ...        ...    ...   \n",
    "1851          0        3          1        0     0      1          0      0   \n",
    "1852          0        3          1        0     0      1          0      0   \n",
    "1853          0        3          1        0     0      1          0      0   \n",
    "1854          0        3          1        0     0      1          0      0   \n",
    "1855          3        3          1        1     0      0          0      0   \n",
    "\n",
    "      Southeast  West  \n",
    "0             0     0  \n",
    "1             0     0  \n",
    "2             0     0  \n",
    "3             0     0  \n",
    "4             0     0  \n",
    "...         ...   ...  \n",
    "1851          0     0  \n",
    "1852          0     0  \n",
    "1853          0     0  \n",
    "1854          0     0  \n",
    "1855          0     0  \n",
    "\n",
    "[1739 rows x 47 columns]\n",
    "1\n",
    "rModel3 = sm.OLS(y_train, X_train).fit()\n",
    "2\n",
    "# Fit the model\n",
    "3\n",
    "#rModel3_results = rModel3.fit()\n",
    "4\n",
    "print(rModel3.summary())\n",
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                  Price   R-squared:                       0.779\n",
    "Model:                            OLS   Adj. R-squared:                  0.769\n",
    "Method:                 Least Squares   F-statistic:                     79.17\n",
    "Date:                Sun, 10 Oct 2021   Prob (F-statistic):          3.31e-244\n",
    "Time:                        16:18:28   Log-Likelihood:                -13754.\n",
    "No. Observations:                 869   AIC:                         2.758e+04\n",
    "Df Residuals:                     831   BIC:                         2.776e+04\n",
    "Df Model:                          37                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "=======================================================================================\n",
    "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
    "---------------------------------------------------------------------------------------\n",
    "const               -3.312e+06   3.56e+05     -9.315      0.000   -4.01e+06   -2.61e+06\n",
    "Area                 9229.4578    298.190     30.952      0.000    8644.163    9814.752\n",
    "Bedrooms            -9.351e+05   1.69e+05     -5.546      0.000   -1.27e+06   -6.04e+05\n",
    "Resale              -8.546e+05   3.53e+05     -2.424      0.016   -1.55e+06   -1.63e+05\n",
    "MaintenanceStaff     5.227e+05   2.52e+05      2.077      0.038    2.88e+04    1.02e+06\n",
    "Gymnasium            1.792e+05   3.31e+05      0.541      0.589   -4.71e+05    8.29e+05\n",
    "SwimmingPool         6.632e+05   2.44e+05      2.713      0.007    1.83e+05    1.14e+06\n",
    "LandscapedGardens   -8.228e+05   2.24e+05     -3.678      0.000   -1.26e+06   -3.84e+05\n",
    "JoggingTrack        -2.157e+05   2.16e+05     -0.999      0.318    -6.4e+05    2.08e+05\n",
    "RainWaterHarvesting  5.015e+05   2.02e+05      2.489      0.013    1.06e+05    8.97e+05\n",
    "IndoorGames         -3.308e+05   1.77e+05     -1.867      0.062   -6.78e+05    1.69e+04\n",
    "ShoppingMall         1.802e+06   2.86e+05      6.302      0.000    1.24e+06    2.36e+06\n",
    "Intercom            -8.176e+04   1.96e+05     -0.417      0.677   -4.67e+05    3.04e+05\n",
    "SportsFacility        5.36e+04   1.97e+05      0.272      0.786   -3.33e+05    4.41e+05\n",
    "ATM                 -9.322e+05   2.78e+05     -3.351      0.001   -1.48e+06   -3.86e+05\n",
    "ClubHouse            9.259e+05   2.21e+05      4.196      0.000    4.93e+05    1.36e+06\n",
    "School              -2.288e+06   4.66e+05     -4.907      0.000    -3.2e+06   -1.37e+06\n",
    "X24X7Security        2.286e+05    2.3e+05      0.995      0.320   -2.23e+05     6.8e+05\n",
    "PowerBackup         -6.999e+05   3.44e+05     -2.033      0.042   -1.38e+06   -2.43e+04\n",
    "CarParking           2.343e+05   1.76e+05      1.332      0.183   -1.11e+05     5.8e+05\n",
    "StaffQuarter         1.053e+06   2.57e+05      4.091      0.000    5.48e+05    1.56e+06\n",
    "Cafeteria           -4.117e+05   1.85e+05     -2.231      0.026   -7.74e+05   -4.95e+04\n",
    "MultipurposeRoom      3.87e+05   1.87e+05      2.071      0.039    2.03e+04    7.54e+05\n",
    "Hospital            -1.513e+05   5.76e+05     -0.263      0.793   -1.28e+06    9.79e+05\n",
    "WashingMachine       6.402e+05   3.72e+05      1.722      0.085   -8.96e+04    1.37e+06\n",
    "Gasconnection        1.223e+06   2.85e+05      4.290      0.000    6.64e+05    1.78e+06\n",
    "AC                   7.531e+05   1.35e+06      0.557      0.578    -1.9e+06    3.41e+06\n",
    "Childrensplayarea   -1.056e+06   2.47e+05     -4.280      0.000   -1.54e+06   -5.72e+05\n",
    "LiftAvailable         8.14e+05   2.39e+05      3.406      0.001    3.45e+05    1.28e+06\n",
    "BED                 -2.159e+06   1.29e+06     -1.669      0.095    -4.7e+06     3.8e+05\n",
    "VaastuCompliant     -3.535e+05   1.91e+05     -1.850      0.065   -7.29e+05    2.16e+04\n",
    "Microwave            6.402e+05   3.72e+05      1.722      0.085   -8.96e+04    1.37e+06\n",
    "GolfCourse          -4.923e+05   3.76e+05     -1.310      0.190   -1.23e+06    2.45e+05\n",
    "TV                   6.402e+05   3.72e+05      1.722      0.085   -8.96e+04    1.37e+06\n",
    "DiningTable          6.402e+05   3.72e+05      1.722      0.085   -8.96e+04    1.37e+06\n",
    "Sofa                 6.402e+05   3.72e+05      1.722      0.085   -8.96e+04    1.37e+06\n",
    "Refrigerator         6.402e+05   3.72e+05      1.722      0.085   -8.96e+04    1.37e+06\n",
    "Furniture           -8.784e+05   5.96e+05     -1.473      0.141   -2.05e+06    2.92e+05\n",
    "Fitness               1.88e+05   9.94e+04      1.892      0.059   -7086.742    3.83e+05\n",
    "Entertain            2946.0036   1.09e+05      0.027      0.978   -2.11e+05    2.17e+05\n",
    "Central              2.896e+05   1.69e+05      1.712      0.087   -4.25e+04    6.22e+05\n",
    "East                -4.567e+05   2.31e+05     -1.977      0.048    -9.1e+05   -3347.496\n",
    "North                7.288e+05   2.11e+05      3.448      0.001    3.14e+05    1.14e+06\n",
    "Northeast           -1.178e+06   4.77e+05     -2.470      0.014   -2.11e+06   -2.42e+05\n",
    "South               -7.353e+05   1.48e+05     -4.976      0.000   -1.03e+06   -4.45e+05\n",
    "Southeast           -1.143e+06   2.56e+05     -4.464      0.000   -1.65e+06    -6.4e+05\n",
    "West                -8.181e+05   2.47e+05     -3.318      0.001    -1.3e+06   -3.34e+05\n",
    "==============================================================================\n",
    "Omnibus:                      139.282   Durbin-Watson:                   2.089\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              518.657\n",
    "Skew:                           0.723   Prob(JB):                    2.37e-113\n",
    "Kurtosis:                       6.498   Cond. No.                     1.25e+17\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The smallest eigenvalue is 1.1e-25. This might indicate that there are\n",
    "strong multicollinearity problems or that the design matrix is singular.\n",
    "1\n",
    "model = LinearRegression()\n",
    "2\n",
    "model.fit(X_train, y_train)\n",
    "3\n",
    "print(model.coef_)\n",
    "4\n",
    "pd.DataFrame(model.coef_, X.columns, columns = ['Coeff'])\n",
    "5\n",
    "predictions = model.predict(X_test)\n",
    "6\n",
    "​\n",
    "7\n",
    "​\n",
    "[-1.36e-08  9.23e+03 -9.35e+05 -8.55e+05  5.23e+05  1.79e+05  6.63e+05\n",
    " -8.23e+05 -2.16e+05  5.02e+05 -3.31e+05  1.80e+06 -8.18e+04  5.36e+04\n",
    " -9.32e+05  9.26e+05 -2.29e+06  2.29e+05 -7.00e+05  2.34e+05  1.05e+06\n",
    " -4.12e+05  3.87e+05 -1.51e+05  6.40e+05  1.22e+06  7.53e+05 -1.06e+06\n",
    "  8.14e+05 -2.16e+06 -3.53e+05  6.40e+05 -4.92e+05  6.40e+05  6.40e+05\n",
    "  6.40e+05  6.40e+05 -8.78e+05  1.88e+05  2.95e+03  7.63e+05  1.65e+04\n",
    "  1.20e+06 -7.04e+05 -2.62e+05 -6.70e+05 -3.45e+05]\n",
    "1\n",
    "metrics.mean_absolute_error(y_test, predictions)\n",
    "1352160.9274540052\n",
    "Using a learning rate of 0.5 we get a mean absolute error of 1.35 x10^6 that is a good error since our min apartment price is around $10 million.\n",
    "\n",
    "1.7.3.1  Visualizing our predictions\n",
    "\n",
    "1\n",
    "fig = plt.figure(figsize= (10, 10))\n",
    "2\n",
    "ax = fig.add_subplot(111)\n",
    "3\n",
    "ax.set_title(\"Prediction of Property Prices\", fontsize= 20)\n",
    "4\n",
    "ax.set\n",
    "5\n",
    "ax.hist(y_test - predictions, color ='maroon', bins=10, edgecolor=\"white\")\n",
    "6\n",
    "plt.xlabel(\"Price in Millions\")\n",
    "7\n",
    "plt.ylabel(\"Properties\")\n",
    "8\n",
    "​\n",
    "9\n",
    "plt.show()\n",
    "10\n",
    "​\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
